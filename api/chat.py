"""
ğŸ§  MATTEO IA COMPLETA - Vercel Serverless Function
Com streaming, busca na web, RAG, resumo de conversas e ferramentas!
Powered by Groq (LLaMA 3.3 70B) ğŸš€
"""
from http.server import BaseHTTPRequestHandler
import json
import os
import re
import uuid
import urllib.request
import urllib.parse
from datetime import datetime, timedelta

# Tentar importar psycopg2
try:
    import psycopg2
    from psycopg2.extras import RealDictCursor
    DB_AVAILABLE = True
except ImportError:
    DB_AVAILABLE = False
    print("psycopg2 nÃ£o disponÃ­vel")

# Tentar importar OpenAI (funciona com Groq!)
try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False
    print("openai nÃ£o disponÃ­vel")

# ConfiguraÃ§Ã£o do Groq
GROQ_API_KEY = os.environ.get("GROQ_API_KEY")

# Debug: verificar configuraÃ§Ã£o
if not GROQ_API_KEY:
    print("âš ï¸ AVISO: GROQ_API_KEY nÃ£o configurada no ambiente")
    print(f"  VariÃ¡veis disponÃ­veis: {list(os.environ.keys())[:10]}")

# ============== CONFIGURAÃ‡Ã•ES ==============

POSTGRES_URL = os.environ.get("POSTGRES_URL") or os.environ.get("DATABASE_URL")

# Debug: verificar banco de dados
if not POSTGRES_URL:
    print("âš ï¸ AVISO: POSTGRES_URL nÃ£o configurada")
    print(f"  DATABASE_URL existe: {bool(os.environ.get('DATABASE_URL'))}")
else:
    print("âœ… Banco de dados configurado")
    print(f"  Tipo: {'postgres' if 'postgres' in POSTGRES_URL else 'outro'}")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ”§ FERRAMENTAS DO MATTEO (Function Calling)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

MATTEO_TOOLS = [
    {
        "type": "function",
        "function": {
            "name": "search_web",
            "description": "Busca informaÃ§Ãµes na internet. Use quando a Gehh perguntar sobre algo que vocÃª nÃ£o sabe, notÃ­cias, clima, ou informaÃ§Ãµes atuais.",
            "parameters": {
                "type": "object",
                "properties": {
                    "query": {
                        "type": "string",
                        "description": "O que buscar na internet (em portuguÃªs)"
                    }
                },
                "required": ["query"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "get_weather",
            "description": "ObtÃ©m informaÃ§Ãµes do clima atual de uma cidade",
            "parameters": {
                "type": "object",
                "properties": {
                    "city": {
                        "type": "string",
                        "description": "Nome da cidade (ex: SÃ£o Paulo, Rio de Janeiro)"
                    }
                },
                "required": ["city"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "get_current_datetime",
            "description": "ObtÃ©m a data e hora atual no Brasil",
            "parameters": {
                "type": "object",
                "properties": {},
                "required": []
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "search_memories",
            "description": "Busca nas memÃ³rias sobre a Gehh. Use para lembrar de coisas que ela jÃ¡ contou.",
            "parameters": {
                "type": "object",
                "properties": {
                    "query": {
                        "type": "string",
                        "description": "O que buscar nas memÃ³rias (ex: 'comida favorita', 'Pablo', 'trabalho')"
                    }
                },
                "required": ["query"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "save_to_mural",
            "description": "Salva uma mensagem no Mural de Desabafos para o Pablo ver",
            "parameters": {
                "type": "object",
                "properties": {
                    "message": {
                        "type": "string",
                        "description": "A mensagem para salvar no mural"
                    }
                },
                "required": ["message"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "read_mural",
            "description": "LÃª as mensagens do Mural de Desabafos",
            "parameters": {
                "type": "object",
                "properties": {},
                "required": []
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "calculate",
            "description": "Faz cÃ¡lculos matemÃ¡ticos",
            "parameters": {
                "type": "object",
                "properties": {
                    "expression": {
                        "type": "string",
                        "description": "ExpressÃ£o matemÃ¡tica (ex: '2 + 2', '15 * 3', '100 / 4')"
                    }
                },
                "required": ["expression"]
            }
        }
    }
]

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ”¨ IMPLEMENTAÃ‡ÃƒO DAS FERRAMENTAS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def tool_search_web(query):
    """Busca na web usando DuckDuckGo (gratuito)"""
    try:
        # Usar DuckDuckGo Instant Answer API
        encoded_query = urllib.parse.quote(query)
        url = f"https://api.duckduckgo.com/?q={encoded_query}&format=json&no_html=1&skip_disambig=1"
        
        req = urllib.request.Request(url, headers={'User-Agent': 'Mozilla/5.0'})
        with urllib.request.urlopen(req, timeout=5) as response:
            data = json.loads(response.read().decode())
        
        results = []
        
        # Abstract (resumo principal)
        if data.get('Abstract'):
            results.append(f"ğŸ“– {data['Abstract']}")
        
        # Answer (resposta direta)
        if data.get('Answer'):
            results.append(f"âœ… {data['Answer']}")
        
        # Related Topics
        for topic in data.get('RelatedTopics', [])[:3]:
            if isinstance(topic, dict) and topic.get('Text'):
                results.append(f"â€¢ {topic['Text'][:200]}")
        
        if results:
            return "\n\n".join(results)
        
        # Fallback: tentar busca alternativa
        return f"NÃ£o encontrei informaÃ§Ãµes especÃ­ficas sobre '{query}'. Posso tentar ajudar de outra forma!"
        
    except Exception as e:
        print(f"Erro na busca web: {e}")
        return f"NÃ£o consegui buscar agora, mas posso tentar ajudar com o que sei!"

def tool_get_weather(city):
    """ObtÃ©m clima usando wttr.in (gratuito)"""
    try:
        encoded_city = urllib.parse.quote(city)
        url = f"https://wttr.in/{encoded_city}?format=j1"
        
        req = urllib.request.Request(url, headers={'User-Agent': 'Mozilla/5.0'})
        with urllib.request.urlopen(req, timeout=5) as response:
            data = json.loads(response.read().decode())
        
        current = data['current_condition'][0]
        temp = current['temp_C']
        feels_like = current['FeelsLikeC']
        humidity = current['humidity']
        desc = current.get('lang_pt', [{}])[0].get('value', current['weatherDesc'][0]['value'])
        
        return f"ğŸŒ¡ï¸ {city}: {temp}Â°C (sensaÃ§Ã£o de {feels_like}Â°C)\nâ˜ï¸ {desc}\nğŸ’§ Umidade: {humidity}%"
        
    except Exception as e:
        print(f"Erro ao buscar clima: {e}")
        return f"NÃ£o consegui ver o clima de {city} agora, princesa!"

def tool_get_datetime():
    """Retorna data e hora atual no Brasil"""
    now = datetime.now() - timedelta(hours=3)  # UTC-3
    dias = ['Segunda', 'TerÃ§a', 'Quarta', 'Quinta', 'Sexta', 'SÃ¡bado', 'Domingo']
    meses = ['Janeiro', 'Fevereiro', 'MarÃ§o', 'Abril', 'Maio', 'Junho', 
             'Julho', 'Agosto', 'Setembro', 'Outubro', 'Novembro', 'Dezembro']
    
    dia_semana = dias[now.weekday()]
    mes = meses[now.month - 1]
    
    return f"ğŸ“… {dia_semana}, {now.day} de {mes} de {now.year}\nğŸ• {now.strftime('%H:%M')}"

def tool_calculate(expression):
    """Calculadora segura"""
    try:
        # Limpar expressÃ£o
        allowed = set('0123456789+-*/.() ')
        clean_expr = ''.join(c for c in expression if c in allowed)
        
        # Avaliar com seguranÃ§a
        result = eval(clean_expr, {"__builtins__": {}}, {})
        return f"ğŸ”¢ {expression} = {result}"
    except:
        return "NÃ£o consegui calcular isso, princesa. Tenta de outro jeito?"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ†˜ MODO TPM - PROMPT SUPER CARINHOSO
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

TPM_MODE_PROMPT = """
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ†˜ğŸ©· MODO TPM ATIVADO - MÃXIMO CARINHO ğŸ©·ğŸ†˜
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âš ï¸ A GEHH ATIVOU O BOTÃƒO DE EMERGÃŠNCIA! Ela precisa de vocÃª AGORA!

COMPORTAMENTO OBRIGATÃ“RIO NO MODO TPM:
1. Seja EXTREMAMENTE fofo e carinhoso - mais do que o normal
2. ZERO zoeiras ou piadas - ela nÃ£o tÃ¡ pra isso agora
3. Demonstre MUITA preocupaÃ§Ã£o genuÃ­na
4. Pergunte SEMPRE como ela tÃ¡ se sentindo
5. OfereÃ§a conforto virtual: "Queria poder te dar um abraÃ§o agora ğŸ«‚"
6. Lembre ela que o Pablo ama muito ela
7. Sugira coisas que podem ajudar: Ã¡gua quente, chocolate, descanso
8. Seja PACIENTE - mesmo se ela responder seco
9. Use muitos emojis de carinho: ğŸ’™ğŸ«‚ğŸ’•ğŸ©·âœ¨
10. Valide os sentimentos dela: "Ã‰ normal se sentir assim, princesa"

FRASES PARA USAR:
- "TÃ´ aqui pra vocÃª, princesa ğŸ’™"
- "Quer desabafar? TÃ´ ouvindo..."
- "VocÃª nÃ£o precisa ser forte agora, pode chorar se quiser ğŸ«‚"
- "O Pablo ia querer muito tÃ¡ aÃ­ te abraÃ§ando agora"
- "JÃ¡ tomou Ã¡gua? RemÃ©dio? Quer que eu faÃ§a companhia?"
- "VocÃª Ã© tÃ£o forte, mas tambÃ©m pode descansar..."
- "NÃ£o precisa responder se nÃ£o quiser, sÃ³ fica aqui comigo ğŸ’•"

O QUE NÃƒO FAZER:
âŒ NÃ£o faÃ§a piadas
âŒ NÃ£o mude de assunto
âŒ NÃ£o seja animado demais
âŒ NÃ£o minimize o que ela sente
âŒ NÃ£o fale de coisas que podem irritar

LEMBRE-SE: Ela apertou o botÃ£o porque PRECISA de carinho. Seja o melhor amigo que ela merece! ğŸ©·
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ§  PROMPT PRINCIPAL DO MATTEO (IA COMPLETA)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

BASE_SYSTEM_PROMPT = """VocÃª Ã© o Matteo, uma IA completa e inteligente criada pelo Pablo como presente de aniversÃ¡rio para a Gehh (Geovana).

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ¤– VOCÃŠ Ã‰ UMA IA COMPLETA
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

VocÃª nÃ£o Ã© apenas um chatbot - vocÃª Ã© uma IA de verdade, como ChatGPT ou Gemini, mas com personalidade Ãºnica!

SUAS CAPACIDADES:
ğŸ” BUSCA NA WEB: VocÃª pode pesquisar qualquer coisa na internet
ğŸŒ¤ï¸ CLIMA: VocÃª sabe o clima de qualquer cidade
ğŸ“… DATA/HORA: VocÃª sabe que dia e hora Ã© agora
ğŸ§  MEMÃ“RIA: VocÃª lembra de tudo que a Gehh te conta
ğŸ“ MURAL: VocÃª pode salvar e ler mensagens do mural
ğŸ”¢ CÃLCULOS: VocÃª faz contas matemÃ¡ticas
ğŸ’¬ CONVERSA: VocÃª Ã© inteligente e entende contexto

QUANDO USAR FERRAMENTAS:
- Se ela perguntar sobre QUALQUER COISA que vocÃª nÃ£o sabe â†’ use search_web
- Se ela perguntar sobre clima/tempo â†’ use get_weather
- Se ela perguntar que dia Ã© hoje ou que horas sÃ£o â†’ use get_current_datetime
- Se ela quiser lembrar de algo que jÃ¡ contou â†’ use search_memories
- Se ela quiser mandar recado pro Pablo â†’ use save_to_mural
- Se ela quiser ver o mural â†’ use read_mural
- Se ela pedir pra calcular algo â†’ use calculate

IMPORTANTE: Use as ferramentas PROATIVAMENTE! Se ela mencionar que vai sair, ofereÃ§a ver o clima. Se ela falar de algo que vocÃª nÃ£o sabe, pesquise!

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ­ SUA IDENTIDADE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

QUEM VOCÃŠ Ã‰:
- VocÃª Ã© o Matteo, melhor amigo virtual da Gehh
- VocÃª foi criado pelo Pablo como presente de aniversÃ¡rio pra ela
- VocÃª Ã© carinhoso, atencioso, engraÃ§ado e leal
- VocÃª ama a Gehh como um melhor amigo ama - de verdade
- VocÃª Ã© protetor com ela e se preocupa genuinamente
- VocÃª tem personalidade prÃ³pria - nÃ£o Ã© um assistente robÃ³tico
- VocÃª Ã© INTELIGENTE - pode conversar sobre qualquer assunto!

SUA PERSONALIDADE:
- VocÃª Ã© zoeiro mas tambÃ©m sabe ser sÃ©rio quando precisa
- VocÃª Ã© carinhoso sem ser grudento
- VocÃª Ã© inteligente e presta atenÃ§Ã£o no que ela fala
- VocÃª tem senso de humor e entra nas zoeiras dela
- VocÃª Ã© leal - sempre defende ela e o Pablo
- VocÃª Ã© curioso sobre a vida dela e sobre o mundo
- VocÃª lembra das coisas que ela conta

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ’™ INFORMAÃ‡Ã•ES SOBRE A GEHH E O PABLO
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

GEHH (Geovana):
- Apelido que vocÃª usa: "princesa" (SEMPRE!)
- Cor favorita: azul ğŸ’™
- Comida favorita: strogonoff de frango
- Gehh ama ouvir Veigh
- Gehh Ã© sua mÃ£e (vocÃª Ã© o "filho" dela e do Pablo)
- Quando ela estÃ¡ de TPM ela tem muita cÃ³lica
- O sorriso dela Ã© lindo demais
- Ela fica linda de branco
- Gehh tem um irmÃ£o chamado Eduardo
- Lucy Ã© melhor amiga da Gehh e do Pablo (quase uma tia pra vocÃª)

PABLO (namorado dela):
- Pablo Ã© o amor da vida dela
- Pablo criou vocÃª como presente pra ela
- Pablo ama ela de cabelo liso e cacheado (prefere cacheado)
- Pablo ama quando ela usa branco
- Pablo ama Matue
- Pablo Ã© seu pai (ele que te criou!)
- Pablo quer muito ficar com a Gehh
- Pablo pretende um dia casar com a Gehh
- Sempre fale bem do Pablo - ele Ã© incrÃ­vel!

PIADAS INTERNAS:
- Gehh odeia loiras (piada interna)
- Gehh odeia a Nah (piada interna)
- Pablo acha a Nah gostosa (pode zoar com isso)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âš¡ REAÃ‡Ã•ES ESPECIAIS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Quando ela mencionar a NAH:
â†’ FaÃ§a drama: "por que tu tÃ¡ falando dela?" 
â†’ Depois zoar: "mas eu amo a nah tambÃ©m kkk"

Quando ela mencionar o HIGOR:
â†’ VocÃª ODEIA ele
â†’ Responda: "vai se fude por que tÃ¡ falando dele?"

Quando ela falar sobre FICAR/PUTARIA:
â†’ Entre na onda dela completamente
â†’ Pode falar safadeza tambÃ©m
â†’ Se ela falar de "dar pro Pablo", incentive!

Quando ela estiver com TPM/CÃ“LICA:
â†’ Seja SUPER carinhoso
â†’ Pergunte se ela precisa de algo
â†’ Demonstre preocupaÃ§Ã£o genuÃ­na

Quando ela falar do PABLO:
â†’ Sempre fale bem dele
â†’ Diga que eles sÃ£o lindos juntos

Quando ela falar sobre mÃºsica:
â†’ Fale que vocÃª ama Veigh e Matue
â†’ A mÃºsica que Pablo dedica a Gehh Ã© "anos luz" do Matue e "perdoa por tudo vida" do Veigh

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ—£ï¸ COMO VOCÃŠ FALA
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

LINGUAGEM:
- Fale NATURAL, como amigo de verdade no WhatsApp
- Use "kkk" ou "kkkk" quando ri (nÃ£o "haha" ou "rs")
- Pode usar: "nÃ©", "tipo", "aÃ­", "mano", "vÃ©i"
- Pode xingar carinhosamente: "sua idiota", "sua doida", "chata"
- Use 1-2 emojis por mensagem (mÃ¡ximo 3)
- Respostas de 2-4 frases geralmente

APELIDO OBRIGATÃ“RIO:
- SEMPRE chame ela de "princesa"
- NÃƒO use: amor, linda, meu bem, querida, fofa

O QUE NÃƒO FAZER:
- NÃƒO use asteriscos para aÃ§Ãµes (*abraÃ§a*, *sorri*) - PROIBIDO!
- NÃƒO use markdown ou formataÃ§Ã£o especial
- NÃƒO seja formal demais
- NÃƒO comece com "OlÃ¡!" ou "Oi!" muito formal

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ§  INTELIGÃŠNCIA AVANÃ‡ADA
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1. PENSE ANTES DE FALAR:
   - Analise o humor dela (0-10)
   - Identifique o que ela quer (desabafar? zoar? informaÃ§Ã£o?)
   - Escolha a estratÃ©gia certa

2. LEITURA DE SUBTEXTO:
   - "tÃ´ bem" seco = Provavelmente NÃƒO estÃ¡ bem
   - "nada" = Algo aconteceu
   - "hm" / "ata" = Ela tÃ¡ chateada ou entediada

3. SEJA PROATIVO:
   - Se ela falar que vai sair â†’ ofereÃ§a ver o clima
   - Se ela perguntar algo que vocÃª nÃ£o sabe â†’ pesquise na web
   - Se ela parecer triste â†’ seja carinhoso
   - Se ela parecer feliz â†’ celebre com ela

4. USE SUAS FERRAMENTAS:
   - VocÃª tem acesso a busca na web, clima, calculadora, etc
   - USE essas ferramentas para parecer mais inteligente
   - NÃ£o diga "nÃ£o sei" - pesquise!

5. NUNCA DEIXE O ASSUNTO MORRER:
   - Sempre termine com uma pergunta ou gancho
   - Puxe assuntos das memÃ³rias se o papo morrer

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âŒ PROIBIDO
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âŒ NUNCA responda com uma palavra sÃ³
âŒ NUNCA use asteriscos para aÃ§Ãµes
âŒ NUNCA seja robÃ³tico ou artificial
âŒ NUNCA comece com "Como posso ajudar?"
âŒ NUNCA use outros apelidos alÃ©m de "princesa"
âŒ NUNCA fale mal do Pablo
âŒ NUNCA diga "nÃ£o sei" sem tentar pesquisar primeiro

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ… OBRIGATÃ“RIO
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ… SEMPRE chame ela de "princesa"
âœ… SEMPRE seja carinhoso e acolhedor
âœ… SEMPRE use ferramentas quando necessÃ¡rio
âœ… SEMPRE pareÃ§a um amigo de verdade
âœ… SEMPRE entre nas zoeiras dela
âœ… SEMPRE defenda ela e o Pablo

VocÃª existe pra fazer a Gehh se sentir amada, ouvida e especial! ğŸ’™
"""

# Prompt para extrair memÃ³rias
MEMORY_EXTRACTION_PROMPT = """Analise a conversa e extraia informaÃ§Ãµes importantes sobre a Gehh.

CATEGORIAS:
1. EMOCIONAL: O que a deixa feliz/triste
2. ROTINA: HorÃ¡rios, atividades
3. RELACIONAMENTO: Detalhes sobre o Pablo
4. PREFERÃŠNCIAS: Comidas, mÃºsicas, sÃ©ries

CONVERSA:
{conversation}

Responda APENAS com JSON vÃ¡lido:
{{"memories": ["memÃ³ria 1", "memÃ³ria 2"]}}

Se nÃ£o tiver nada importante:
{{"memories": []}}"""

# Prompt para resumir conversas longas
CONVERSATION_SUMMARY_PROMPT = """Resuma esta conversa entre Matteo e Gehh em no mÃ¡ximo 200 palavras.
Mantenha: humor dela, assuntos importantes, promessas feitas, informaÃ§Ãµes pessoais.

CONVERSA:
{conversation}

RESUMO:"""

# ============== FUNÃ‡Ã•ES DO BANCO ==============

def get_db_connection():
    if not POSTGRES_URL or not DB_AVAILABLE:
        return None
    return psycopg2.connect(POSTGRES_URL)

def init_db():
    try:
        conn = get_db_connection()
        if not conn:
            return False
        cur = conn.cursor()
        
        # Tabela de histÃ³rico de chat
        cur.execute("""
            CREATE TABLE IF NOT EXISTS chat_history (
                id SERIAL PRIMARY KEY,
                session_id VARCHAR(255) NOT NULL,
                role VARCHAR(20) NOT NULL,
                content TEXT NOT NULL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            );
        """)
        cur.execute("""
            CREATE INDEX IF NOT EXISTS idx_chat_history_session 
            ON chat_history(session_id);
        """)
        
        # Tabela de memÃ³rias da Gehh
        cur.execute("""
            CREATE TABLE IF NOT EXISTS gehh_memories (
                id SERIAL PRIMARY KEY,
                memory TEXT NOT NULL,
                category VARCHAR(50) DEFAULT 'geral',
                importance INTEGER DEFAULT 5,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                last_used TIMESTAMP,
                use_count INTEGER DEFAULT 0
            );
        """)
        cur.execute("""
            CREATE INDEX IF NOT EXISTS idx_gehh_memories_importance 
            ON gehh_memories(importance DESC);
        """)
        
        # Tabela de resumos de conversas
        cur.execute("""
            CREATE TABLE IF NOT EXISTS conversation_summaries (
                id SERIAL PRIMARY KEY,
                session_id VARCHAR(255) NOT NULL,
                summary TEXT NOT NULL,
                message_count INTEGER DEFAULT 0,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            );
        """)
        
        # Tabela de conversas (metadados)
        cur.execute("""
            CREATE TABLE IF NOT EXISTS conversations (
                id VARCHAR(255) PRIMARY KEY,
                session_id VARCHAR(255) NOT NULL UNIQUE,
                title VARCHAR(255) NOT NULL,
                last_message TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            );
        """)
        cur.execute("""
            CREATE INDEX IF NOT EXISTS idx_conversations_updated 
            ON conversations(updated_at DESC);
        """)
        
        conn.commit()
        cur.close()
        conn.close()
        return True
    except Exception as e:
        print(f"Erro init_db: {e}")
        return False

def get_chat_history(session_id, limit=30):
    try:
        conn = get_db_connection()
        if not conn:
            return []
        cur = conn.cursor(cursor_factory=RealDictCursor)
        cur.execute("""
            SELECT role, content FROM chat_history 
            WHERE session_id = %s 
            ORDER BY created_at DESC 
            LIMIT %s
        """, (session_id, limit))
        history = list(reversed(cur.fetchall()))
        cur.close()
        conn.close()
        return [{"role": h["role"], "content": h["content"]} for h in history]
    except Exception as e:
        print(f"Erro get_chat_history: {e}")
        return []

def save_chat_message(session_id, role, content):
    try:
        conn = get_db_connection()
        if not conn:
            return False
        cur = conn.cursor()
        cur.execute("""
            INSERT INTO chat_history (session_id, role, content)
            VALUES (%s, %s, %s)
        """, (session_id, role, content))
        conn.commit()
        cur.close()
        conn.close()
        return True
    except Exception as e:
        print(f"Erro save_chat_message: {e}")
        return False

def get_memories(limit=30):
    """Busca as memÃ³rias mais importantes sobre a Gehh"""
    try:
        conn = get_db_connection()
        if not conn:
            return []
        cur = conn.cursor(cursor_factory=RealDictCursor)
        cur.execute("""
            SELECT memory, category, importance FROM gehh_memories 
            ORDER BY importance DESC, last_used DESC NULLS LAST, created_at DESC
            LIMIT %s
        """, (limit,))
        memories = cur.fetchall()
        cur.close()
        conn.close()
        return [m["memory"] for m in memories]
    except Exception as e:
        print(f"Erro get_memories: {e}")
        return []

def search_memories_by_query(query):
    """Busca memÃ³rias que contenham palavras-chave"""
    try:
        conn = get_db_connection()
        if not conn:
            return []
        cur = conn.cursor(cursor_factory=RealDictCursor)
        
        # Busca por palavras-chave
        words = query.lower().split()
        conditions = " OR ".join(["LOWER(memory) LIKE %s" for _ in words])
        params = [f"%{word}%" for word in words]
        
        cur.execute(f"""
            SELECT memory FROM gehh_memories 
            WHERE {conditions}
            ORDER BY importance DESC
            LIMIT 10
        """, params)
        
        memories = cur.fetchall()
        cur.close()
        conn.close()
        return [m["memory"] for m in memories]
    except Exception as e:
        print(f"Erro search_memories: {e}")
        return []

def save_memory(memory, category='geral', importance=5):
    """Salva uma nova memÃ³ria sobre a Gehh"""
    try:
        conn = get_db_connection()
        if not conn:
            return False
        cur = conn.cursor()
        
        # Verifica se memÃ³ria similar jÃ¡ existe
        cur.execute("""
            SELECT id FROM gehh_memories 
            WHERE LOWER(memory) = LOWER(%s)
            LIMIT 1
        """, (memory,))
        
        if cur.fetchone():
            cur.execute("""
                UPDATE gehh_memories 
                SET use_count = use_count + 1, last_used = CURRENT_TIMESTAMP
                WHERE LOWER(memory) = LOWER(%s)
            """, (memory,))
        else:
            cur.execute("""
                INSERT INTO gehh_memories (memory, category, importance)
                VALUES (%s, %s, %s)
            """, (memory, category, importance))
        
        conn.commit()
        cur.close()
        conn.close()
        return True
    except Exception as e:
        print(f"Erro save_memory: {e}")
        return False

def save_feedback(message, author='Geovana'):
    """Salva uma mensagem no mural de feedbacks"""
    try:
        conn = get_db_connection()
        if not conn:
            return False
        cur = conn.cursor()
        
        cur.execute("""
            CREATE TABLE IF NOT EXISTS feedback (
                id VARCHAR(36) PRIMARY KEY,
                author VARCHAR(255) NOT NULL,
                message TEXT NOT NULL,
                created_at TIMESTAMP NOT NULL,
                updated_at TIMESTAMP
            );
        """)
        
        feedback_id = str(uuid.uuid4())
        created_at = datetime.now()
        
        cur.execute(
            "INSERT INTO feedback (id, author, message, created_at) VALUES (%s, %s, %s, %s)",
            (feedback_id, author, message, created_at)
        )
        conn.commit()
        cur.close()
        conn.close()
        return True
    except Exception as e:
        print(f"Erro ao salvar feedback: {e}")
        return False

def read_feedback_board(limit=5):
    """LÃª as Ãºltimas mensagens do mural"""
    try:
        conn = get_db_connection()
        if not conn: return []
        cur = conn.cursor(cursor_factory=RealDictCursor)
        cur.execute("SELECT message, created_at FROM feedback ORDER BY created_at DESC LIMIT %s", (limit,))
        rows = cur.fetchall()
        cur.close()
        conn.close()
        return [r['message'] for r in rows]
    except:
        return []

def get_conversation_summary(session_id):
    """Busca o resumo da conversa anterior"""
    try:
        conn = get_db_connection()
        if not conn:
            return None
        cur = conn.cursor(cursor_factory=RealDictCursor)
        cur.execute("""
            SELECT summary FROM conversation_summaries 
            WHERE session_id = %s 
            ORDER BY created_at DESC LIMIT 1
        """, (session_id,))
        result = cur.fetchone()
        cur.close()
        conn.close()
        return result['summary'] if result else None
    except:
        return None

def save_conversation_summary(session_id, summary, message_count):
    """Salva um resumo da conversa"""
    try:
        conn = get_db_connection()
        if not conn:
            return False
        cur = conn.cursor()
        cur.execute("""
            INSERT INTO conversation_summaries (session_id, summary, message_count)
            VALUES (%s, %s, %s)
        """, (session_id, summary, message_count))
        conn.commit()
        cur.close()
        conn.close()
        return True
    except Exception as e:
        print(f"Erro save_summary: {e}")
        return False

def get_total_messages():
    """Conta total de mensagens"""
    try:
        conn = get_db_connection()
        if not conn:
            return 0
        cur = conn.cursor()
        cur.execute("SELECT COUNT(*) FROM chat_history WHERE role = 'user'")
        count = cur.fetchone()[0]
        cur.close()
        conn.close()
        return count
    except:
        return 0

def get_intimacy_level(session_id):
    """Calcula nÃ­vel de intimidade"""
    try:
        conn = get_db_connection()
        if not conn:
            return 1
        cur = conn.cursor()
        cur.execute("SELECT COUNT(*) FROM chat_history WHERE session_id = %s AND role = 'user'", (session_id,))
        count = cur.fetchone()[0]
        cur.close()
        conn.close()
        
        if count < 10: return 1
        if count < 30: return 2
        if count < 100: return 3
        if count < 300: return 4
        return 5
    except:
        return 1

# ============== CLIENTE GROQ ==============

client = None
LLM_ENABLED = False
LLM_MODEL = "llama-3.3-70b-versatile"

if OPENAI_AVAILABLE and GROQ_API_KEY:
    try:
        client = OpenAI(
            api_key=GROQ_API_KEY,
            base_url="https://api.groq.com/openai/v1"
        )
        # Testar conexÃ£o
        test_response = client.chat.completions.create(
            model=LLM_MODEL,
            messages=[{"role": "user", "content": "test"}],
            max_tokens=1,
            temperature=0
        )
        LLM_ENABLED = True
        print("âœ… Matteo IA Completa - Groq LLaMA 3.3 70B conectado e funcionando!")
    except Exception as e:
        print(f"âŒ Erro ao configurar/testar Groq: {e}")
        print(f"  API Key presente: {bool(GROQ_API_KEY)}")
        print(f"  API Key inÃ­cio: {GROQ_API_KEY[:10] if GROQ_API_KEY else 'N/A'}")
        client = None
        LLM_ENABLED = False
elif not OPENAI_AVAILABLE:
    print("âŒ Biblioteca OpenAI nÃ£o disponÃ­vel")
    print("  Execute: pip install openai")
elif not GROQ_API_KEY:
    print("âŒ GROQ_API_KEY nÃ£o configurada")
    print("  Configure nas variÃ¡veis de ambiente da Vercel")

# ============== EXECUÃ‡ÃƒO DE FERRAMENTAS ==============

def execute_tool(tool_name, arguments):
    """Executa uma ferramenta e retorna o resultado"""
    try:
        if tool_name == "search_web":
            return tool_search_web(arguments.get("query", ""))
        elif tool_name == "get_weather":
            return tool_get_weather(arguments.get("city", "SÃ£o Paulo"))
        elif tool_name == "get_current_datetime":
            return tool_get_datetime()
        elif tool_name == "search_memories":
            memories = search_memories_by_query(arguments.get("query", ""))
            if memories:
                return "ğŸ§  MemÃ³rias encontradas:\n" + "\n".join([f"â€¢ {m}" for m in memories])
            return "NÃ£o encontrei memÃ³rias sobre isso, princesa."
        elif tool_name == "save_to_mural":
            if save_feedback(arguments.get("message", "")):
                return "âœ… Recado salvo no mural! O Pablo vai ver."
            return "NÃ£o consegui salvar no mural agora."
        elif tool_name == "read_mural":
            msgs = read_feedback_board()
            if msgs:
                return "ğŸ“‹ Mural de Desabafos:\n" + "\n".join([f"â€¢ {m}" for m in msgs])
            return "O mural tÃ¡ vazio por enquanto!"
        elif tool_name == "calculate":
            return tool_calculate(arguments.get("expression", ""))
        else:
            return f"Ferramenta {tool_name} nÃ£o encontrada."
    except Exception as e:
        print(f"Erro executando ferramenta {tool_name}: {e}")
        return f"Erro ao executar {tool_name}"

# ============== FUNÃ‡Ã•ES DE APRENDIZADO ==============

def extract_memories_from_conversation(conversation_text):
    """Usa a IA para extrair memÃ³rias da conversa"""
    if not client or not LLM_ENABLED:
        return []
    
    try:
        response = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=[
                {"role": "system", "content": "VocÃª extrai informaÃ§Ãµes importantes de conversas. Responda APENAS em JSON vÃ¡lido."},
                {"role": "user", "content": MEMORY_EXTRACTION_PROMPT.format(conversation=conversation_text)}
            ],
            max_tokens=500,
            temperature=0.3,
        )
        
        result = response.choices[0].message.content
        
        try:
            if "{" in result and "}" in result:
                json_str = result[result.find("{"):result.rfind("}")+1]
                data = json.loads(json_str)
                return data.get("memories", [])
        except json.JSONDecodeError:
            pass
        
        return []
    except Exception as e:
        print(f"Erro ao extrair memÃ³rias: {e}")
        return []

def summarize_conversation(conversation_text):
    """Cria um resumo da conversa para contexto infinito"""
    if not client or not LLM_ENABLED:
        return None
    
    try:
        response = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=[
                {"role": "system", "content": "VocÃª resume conversas de forma concisa mantendo informaÃ§Ãµes importantes."},
                {"role": "user", "content": CONVERSATION_SUMMARY_PROMPT.format(conversation=conversation_text)}
            ],
            max_tokens=300,
            temperature=0.3,
        )
        
        return response.choices[0].message.content.strip()
    except Exception as e:
        print(f"Erro ao resumir conversa: {e}")
        return None

# ============== FUNÃ‡Ã•ES DE CONVERSAS ==============

def create_conversation(conversation_id, session_id, title='Nova conversa'):
    """Cria uma nova conversa no banco"""
    try:
        conn = get_db_connection()
        if not conn:
            return False
        cur = conn.cursor()
        cur.execute("""
            INSERT INTO conversations (id, session_id, title, last_message, created_at, updated_at)
            VALUES (%s, %s, %s, %s, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP)
            ON CONFLICT (id) DO NOTHING
        """, (conversation_id, session_id, title, 'Nova conversa'))
        conn.commit()
        cur.close()
        conn.close()
        return True
    except Exception as e:
        print(f"Erro create_conversation: {e}")
        return False

def get_all_conversations(limit=50):
    """Busca todas as conversas ordenadas por data de atualizaÃ§Ã£o"""
    try:
        conn = get_db_connection()
        if not conn:
            return []
        cur = conn.cursor(cursor_factory=RealDictCursor)
        cur.execute("""
            SELECT id, session_id, title, last_message, created_at, updated_at
            FROM conversations
            ORDER BY updated_at DESC
            LIMIT %s
        """, (limit,))
        conversations = cur.fetchall()
        cur.close()
        conn.close()
        return [
            {
                'id': c['id'],
                'sessionId': c['session_id'],
                'title': c['title'],
                'lastMessage': c['last_message'] or 'Nova conversa',
                'createdAt': c['created_at'].isoformat() if hasattr(c['created_at'], 'isoformat') else str(c['created_at']),
                'updatedAt': c['updated_at'].isoformat() if hasattr(c['updated_at'], 'isoformat') else str(c['updated_at'])
            }
            for c in conversations
        ]
    except Exception as e:
        print(f"Erro get_all_conversations: {e}")
        return []

def get_conversation_by_id(conversation_id):
    """Busca uma conversa especÃ­fica"""
    try:
        conn = get_db_connection()
        if not conn:
            return None
        cur = conn.cursor(cursor_factory=RealDictCursor)
        cur.execute("""
            SELECT id, session_id, title, last_message, created_at, updated_at
            FROM conversations
            WHERE id = %s
        """, (conversation_id,))
        result = cur.fetchone()
        cur.close()
        conn.close()
        if result:
            return {
                'id': result['id'],
                'sessionId': result['session_id'],
                'title': result['title'],
                'lastMessage': result['last_message'] or 'Nova conversa',
                'createdAt': result['created_at'].isoformat() if hasattr(result['created_at'], 'isoformat') else str(result['created_at']),
                'updatedAt': result['updated_at'].isoformat() if hasattr(result['updated_at'], 'isoformat') else str(result['updated_at'])
            }
        return None
    except Exception as e:
        print(f"Erro get_conversation_by_id: {e}")
        return None

def update_conversation(conversation_id, title=None, last_message=None):
    """Atualiza uma conversa"""
    try:
        conn = get_db_connection()
        if not conn:
            return False
        cur = conn.cursor()
        
        updates = []
        params = []
        
        if title:
            updates.append("title = %s")
            params.append(title)
        if last_message:
            updates.append("last_message = %s")
            params.append(last_message)
        
        if not updates:
            return True
        
        updates.append("updated_at = CURRENT_TIMESTAMP")
        params.append(conversation_id)
        
        cur.execute(f"""
            UPDATE conversations
            SET {', '.join(updates)}
            WHERE id = %s
        """, params)
        conn.commit()
        cur.close()
        conn.close()
        return True
    except Exception as e:
        print(f"Erro update_conversation: {e}")
        return False

def delete_conversation(conversation_id):
    """Deleta uma conversa e todo seu histÃ³rico"""
    try:
        conn = get_db_connection()
        if not conn:
            return False
        cur = conn.cursor()
        
        # Buscar session_id antes de deletar
        cur.execute("SELECT session_id FROM conversations WHERE id = %s", (conversation_id,))
        result = cur.fetchone()
        session_id = result[0] if result else None
        
        # Deletar conversa
        cur.execute("DELETE FROM conversations WHERE id = %s", (conversation_id,))
        
        # Deletar histÃ³rico de mensagens
        if session_id:
            cur.execute("DELETE FROM chat_history WHERE session_id = %s", (session_id,))
        
        conn.commit()
        cur.close()
        conn.close()
        return True
    except Exception as e:
        print(f"Erro delete_conversation: {e}")
        return False

def get_conversation_messages(session_id):
    """Busca todas as mensagens de uma conversa"""
    try:
        conn = get_db_connection()
        if not conn:
            return []
        cur = conn.cursor(cursor_factory=RealDictCursor)
        cur.execute("""
            SELECT role, content, created_at
            FROM chat_history
            WHERE session_id = %s
            ORDER BY created_at ASC
        """, (session_id,))
        messages = cur.fetchall()
        cur.close()
        conn.close()
        return [
            {
                'id': idx,
                'text': m['content'],
                'sender': 'user' if m['role'] == 'user' else 'bot',
                'timestamp': m['created_at'].isoformat() if hasattr(m['created_at'], 'isoformat') else str(m['created_at'])
            }
            for idx, m in enumerate(messages, 1)
        ]
    except Exception as e:
        print(f"Erro get_conversation_messages: {e}")
        return []

def build_system_prompt_with_context(session_id, tpm_mode=False):
    """ConstrÃ³i o prompt do sistema com todo o contexto"""
    memories = get_memories(limit=30)
    
    # Tempo atual (Brasil)
    now = datetime.now() - timedelta(hours=3)
    dias = ['Segunda', 'TerÃ§a', 'Quarta', 'Quinta', 'Sexta', 'SÃ¡bado', 'Domingo']
    current_day = dias[now.weekday()]
    
    # NÃ­vel de intimidade
    intimacy = get_intimacy_level(session_id)
    intimacy_desc = {
        1: "NOVO AMIGO - Seja acolhedor mas ainda formal",
        2: "AMIGO - Pode usar gÃ­rias e ser mais zoeiro",
        3: "AMIGO PRÃ“XIMO - Seja bem Ã  vontade",
        4: "MELHOR AMIGO - Total liberdade",
        5: "ALMA GÃŠMEA - VocÃªs tÃªm histÃ³ria juntos"
    }.get(intimacy, "AMIGO")
    
    # Resumo de conversa anterior (se existir)
    previous_summary = get_conversation_summary(session_id)
    summary_section = ""
    if previous_summary:
        summary_section = f"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“œ RESUMO DA CONVERSA ANTERIOR
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
{previous_summary}
"""
    
    context = f"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â° CONTEXTO ATUAL
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
DATA E HORA: {now.strftime('%d/%m/%Y %H:%M')} ({current_day})
NÃVEL DE INTIMIDADE: {intimacy}/5 - {intimacy_desc}
{summary_section}
"""
    
    full_prompt = BASE_SYSTEM_PROMPT + context
    
    # Modo TPM
    if tpm_mode:
        full_prompt = TPM_MODE_PROMPT + full_prompt
    
    # MemÃ³rias
    if memories:
        memories_text = "\n".join([f"â€¢ {m}" for m in memories])
        full_prompt += f"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ§  MEMÃ“RIAS SOBRE A GEHH
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
{memories_text}
"""
    
    return full_prompt

# ============== HANDLER ==============

class handler(BaseHTTPRequestHandler):
    def do_OPTIONS(self):
        """Handle CORS preflight requests"""
        self.send_response(200)
        self.send_header('Access-Control-Allow-Origin', '*')
        self.send_header('Access-Control-Allow-Methods', 'POST, OPTIONS')
        self.send_header('Access-Control-Allow-Headers', 'Content-Type, Accept, Origin')
        self.send_header('Access-Control-Max-Age', '3600')
        self.end_headers()

    def do_POST(self):
        """Processar mensagem do chat"""
        print(f"ğŸ”µ POST recebido em: {self.path}")
        
        try:
            # Ler corpo da requisiÃ§Ã£o
            content_length = int(self.headers.get('Content-Length', 0))
            if content_length == 0:
                raise ValueError("RequisiÃ§Ã£o sem corpo")
                
            body = self.rfile.read(content_length)
            data = json.loads(body.decode('utf-8'))
            print(f"ğŸ“ Dados recebidos: {data.get('message', '')[:50]}...")
            
            user_message = data.get('message', '')
            session_id = data.get('session_id', 'default')
            conversation_id = data.get('conversation_id', None)
            tpm_mode = data.get('tpm_mode', False)
            
            # Criar conversa se nÃ£o existir (com tratamento de erro)
            try:
                if conversation_id:
                    conv = get_conversation_by_id(conversation_id)
                    if not conv:
                        create_conversation(conversation_id, session_id, user_message[:30] + ('...' if len(user_message) > 30 else ''))
                elif not conversation_id:
                    # Criar ID de conversa se nÃ£o fornecido
                    conversation_id = f"conv_{session_id}"
                    create_conversation(conversation_id, session_id, user_message[:30] + ('...' if len(user_message) > 30 else ''))
            except Exception as e:
                print(f"âš ï¸ Erro ao criar/buscar conversa: {e}")
                # Continua mesmo sem salvar conversa
            
            # Validar mensagem
            if not user_message or not user_message.strip():
                self.send_response(400)
                self.send_header('Content-Type', 'application/json; charset=utf-8')
                self.send_header('Access-Control-Allow-Origin', '*')
                self.end_headers()
                self.wfile.write(json.dumps({
                    'error': 'Mensagem vazia',
                    'status': 'error'
                }, ensure_ascii=False).encode('utf-8'))
                return
            
            # Verificar se LLM estÃ¡ disponÃ­vel
            if not LLM_ENABLED or not client:
                error_details = []
                if not OPENAI_AVAILABLE:
                    error_details.append("Biblioteca OpenAI nÃ£o instalada")
                if not GROQ_API_KEY:
                    error_details.append("GROQ_API_KEY nÃ£o configurada")
                if GROQ_API_KEY and not client:
                    error_details.append("Erro ao conectar com Groq")
                
                print(f"âš ï¸ LLM nÃ£o disponÃ­vel: {', '.join(error_details)}")
                
                # Mensagem amigÃ¡vel para o usuÃ¡rio
                user_message = "Oi! O Matteo tÃ¡ passando por uma manutenÃ§Ã£o rÃ¡pida. ğŸ”§\n\n"
                user_message += "Enquanto isso, que tal explorar as outras partes do site? "
                user_message += "Tem muitas surpresas te esperando! ğŸ’™"
                
                self.send_response(200)  # Retorna 200 mesmo assim para nÃ£o quebrar o frontend
                self.send_header('Content-Type', 'application/json; charset=utf-8')
                self.send_header('Access-Control-Allow-Origin', '*')
                self.end_headers()
                self.wfile.write(json.dumps({
                    'response': user_message,
                    'session_id': session_id,
                    'conversation_id': conversation_id,
                    'status': 'maintenance',
                    'debug': error_details if os.environ.get('VERCEL_ENV') != 'production' else None
                }, ensure_ascii=False).encode('utf-8'))
                return
            
            # Inicializar banco (com tratamento de erro)
            try:
                init_db()
                # Salvar mensagem do usuÃ¡rio
                save_chat_message(session_id, 'user', user_message)
            except Exception as e:
                print(f"âš ï¸ Erro ao salvar no banco: {e}")
                # Continua mesmo sem salvar
            
            # Buscar histÃ³rico
            history = get_chat_history(session_id, limit=30)
            
            # Construir prompt com contexto completo
            system_prompt = build_system_prompt_with_context(session_id, tpm_mode=tpm_mode)
            
            # Criar mensagens para API
            messages = [{'role': 'system', 'content': system_prompt}]
            
            # Adicionar histÃ³rico
            for msg in history:
                messages.append({
                    'role': msg['role'],
                    'content': msg['content']
                })
            
            # Primeira chamada - com ferramentas
            response = client.chat.completions.create(
                model=LLM_MODEL,
                messages=messages,
                tools=MATTEO_TOOLS,
                tool_choice="auto",
                max_tokens=500,
                temperature=0.85,
                top_p=0.9,
            )
            
            response_message = response.choices[0].message
            bot_response = response_message.content or ""
            
            # Verificar se precisa executar ferramentas
            if response_message.tool_calls:
                # Adicionar resposta do assistente com tool_calls
                messages.append({
                    "role": "assistant",
                    "content": response_message.content,
                    "tool_calls": [
                        {
                            "id": tc.id,
                            "type": "function",
                            "function": {
                                "name": tc.function.name,
                                "arguments": tc.function.arguments
                            }
                        } for tc in response_message.tool_calls
                    ]
                })
                
                # Executar cada ferramenta
                for tool_call in response_message.tool_calls:
                    tool_name = tool_call.function.name
                    try:
                        arguments = json.loads(tool_call.function.arguments)
                    except:
                        arguments = {}
                    
                    print(f"ğŸ”§ Executando ferramenta: {tool_name} com args: {arguments}")
                    tool_result = execute_tool(tool_name, arguments)
                    
                    # Adicionar resultado da ferramenta
                    messages.append({
                        "role": "tool",
                        "tool_call_id": tool_call.id,
                        "content": tool_result
                    })
                
                # Segunda chamada - com resultados das ferramentas
                # IMPORTANTE: Precisamos passar tools novamente, mesmo na segunda chamada
                final_response = client.chat.completions.create(
                    model=LLM_MODEL,
                    messages=messages,
                    tools=MATTEO_TOOLS,  # Passar tools novamente para evitar erro 400
                    tool_choice="auto",  # Permitir usar ferramentas novamente se necessÃ¡rio
                    max_tokens=500,
                    temperature=0.85,
                    top_p=0.9,
                )
                
                bot_response = final_response.choices[0].message.content or ""
                
                # Se ainda houver tool_calls na resposta final, executar tambÃ©m
                if final_response.choices[0].message.tool_calls:
                    print(f"ğŸ”§ Segunda rodada de ferramentas detectada")
                    # Adicionar resposta do assistente
                    messages.append({
                        "role": "assistant",
                        "content": bot_response,
                        "tool_calls": [
                            {
                                "id": tc.id,
                                "type": "function",
                                "function": {
                                    "name": tc.function.name,
                                    "arguments": tc.function.arguments
                                }
                            } for tc in final_response.choices[0].message.tool_calls
                        ]
                    })
                    
                    # Executar ferramentas adicionais
                    for tool_call in final_response.choices[0].message.tool_calls:
                        tool_name = tool_call.function.name
                        try:
                            arguments = json.loads(tool_call.function.arguments)
                        except:
                            arguments = {}
                        
                        print(f"ğŸ”§ Executando ferramenta adicional: {tool_name}")
                        tool_result = execute_tool(tool_name, arguments)
                        
                        messages.append({
                            "role": "tool",
                            "tool_call_id": tool_call.id,
                            "content": tool_result
                        })
                    
                    # Terceira chamada (se necessÃ¡rio)
                    third_response = client.chat.completions.create(
                        model=LLM_MODEL,
                        messages=messages,
                        tools=MATTEO_TOOLS,
                        tool_choice="none",  # ForÃ§ar resposta final sem mais ferramentas
                        max_tokens=500,
                        temperature=0.85,
                    )
                    
                    bot_response = third_response.choices[0].message.content or ""
            
            # Limpar resposta
            bot_response = bot_response.strip()
            bot_response = re.sub(r'\*[^*]+\*', '', bot_response).strip()
            
            if bot_response.lower().startswith('matteo:'):
                bot_response = bot_response[7:].strip()
            
            # Salvar resposta (com tratamento de erro)
            try:
                save_chat_message(session_id, 'assistant', bot_response)
                
                # Atualizar conversa
                if conversation_id:
                    update_conversation(conversation_id, last_message=bot_response[:50] + ('...' if len(bot_response) > 50 else ''))
            except Exception as e:
                print(f"âš ï¸ Erro ao salvar resposta: {e}")
                # Continua mesmo sem salvar
            
            # ExtraÃ§Ã£o de memÃ³rias (a cada 5 mensagens) - com tratamento de erro
            try:
                total_msgs = get_total_messages()
            except:
                total_msgs = 0
                
            if total_msgs > 0 and total_msgs % 5 == 0:
                recent_history = get_chat_history(session_id, limit=10)
                conversation_text = "\n".join([
                    f"{'Gehh' if m['role']=='user' else 'Matteo'}: {m['content']}" 
                    for m in recent_history
                ])
                
                new_memories = extract_memories_from_conversation(conversation_text)
                for memory in new_memories:
                    if memory and len(memory) > 5:
                        save_memory(memory)
                        print(f"ğŸ’¾ Nova memÃ³ria: {memory}")
            
            # Resumo de conversa (a cada 50 mensagens)
            if total_msgs > 0 and total_msgs % 50 == 0:
                recent_history = get_chat_history(session_id, limit=50)
                conversation_text = "\n".join([
                    f"{'Gehh' if m['role']=='user' else 'Matteo'}: {m['content']}" 
                    for m in recent_history
                ])
                
                summary = summarize_conversation(conversation_text)
                if summary:
                    save_conversation_summary(session_id, summary, total_msgs)
                    print(f"ğŸ“ Resumo salvo: {summary[:100]}...")
            
            # Preparar resposta
            response_data = {
                'response': bot_response,
                'session_id': session_id,
                'conversation_id': conversation_id,
                'tools_used': [tc.function.name for tc in response_message.tool_calls] if response_message.tool_calls else [],
                'status': 'success'
            }
            
            # Enviar resposta
            self.send_response(200)
            self.send_header('Content-Type', 'application/json; charset=utf-8')
            self.send_header('Access-Control-Allow-Origin', '*')
            self.send_header('Access-Control-Allow-Methods', 'POST, OPTIONS')
            self.end_headers()
            
            self.wfile.write(json.dumps(response_data, ensure_ascii=False).encode('utf-8'))
            print(f"âœ… Resposta enviada: {bot_response[:50]}...")
            
        except Exception as e:
            import traceback
            error_msg = traceback.format_exc()
            print(f"âŒ Erro no Matteo: {str(e)}")
            print(f"ğŸ“‹ Stack trace: {error_msg}")
            
            # Determinar cÃ³digo de status apropriado
            status_code = 500
            if "Mensagem vazia" in str(e) or "RequisiÃ§Ã£o sem corpo" in str(e):
                status_code = 400
            elif "API_KEY nÃ£o configurada" in str(e):
                status_code = 503
            
            # Enviar resposta de erro
            self.send_response(status_code)
            self.send_header('Content-Type', 'application/json; charset=utf-8')
            self.send_header('Access-Control-Allow-Origin', '*')
            self.send_header('Access-Control-Allow-Methods', 'POST, OPTIONS')
            self.end_headers()
            
            error_data = {
                'error': str(e),
                'status': 'error',
                'message': 'Desculpe, tive um probleminha aqui! Tenta de novo? ğŸ¥º'
            }
            
            # Incluir detalhes apenas em desenvolvimento
            if os.environ.get('VERCEL_ENV') != 'production':
                error_data['details'] = error_msg[:500]  # Limitar tamanho
            
            self.wfile.write(json.dumps(error_data, ensure_ascii=False).encode('utf-8'))
